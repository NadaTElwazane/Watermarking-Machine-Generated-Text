{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":8094561,"sourceType":"datasetVersion","datasetId":4779182}],"dockerImageVersionId":30666,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T12:26:27.866108Z","iopub.execute_input":"2024-04-14T12:26:27.866472Z","iopub.status.idle":"2024-04-14T12:26:33.439508Z","shell.execute_reply.started":"2024-04-14T12:26:27.866441Z","shell.execute_reply":"2024-04-14T12:26:33.438835Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting nltk\n  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk) (1.3.2)\nRequirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from nltk) (4.66.2)\nInstalling collected packages: nltk\nSuccessfully installed nltk-3.8.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_13/2884944502.py:2: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2024-04-14T12:26:42.669881Z","iopub.execute_input":"2024-04-14T12:26:42.670288Z","iopub.status.idle":"2024-04-14T12:26:49.775424Z","shell.execute_reply.started":"2024-04-14T12:26:42.670258Z","shell.execute_reply":"2024-04-14T12:26:49.774630Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (4.38.1)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers) (4.66.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers) (23.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting sentencepiece\n  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sentencepiece\nSuccessfully installed sentencepiece-0.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndata=pd.read_csv('/kaggle/input/watermarked-and-unwatermarked-text-truncated/data_trunk.csv')\ndata=data.loc[data['label'] == 'watermarked']","metadata":{"execution":{"iopub.status.busy":"2024-04-14T12:33:56.509806Z","iopub.execute_input":"2024-04-14T12:33:56.510425Z","iopub.status.idle":"2024-04-14T12:33:56.544261Z","shell.execute_reply.started":"2024-04-14T12:33:56.510387Z","shell.execute_reply":"2024-04-14T12:33:56.543626Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-14T12:33:59.546035Z","iopub.execute_input":"2024-04-14T12:33:59.546436Z","iopub.status.idle":"2024-04-14T12:33:59.554226Z","shell.execute_reply.started":"2024-04-14T12:33:59.546399Z","shell.execute_reply":"2024-04-14T12:33:59.553644Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                       Generated Text        label\n1   Some companies failed to pay their workers dur...  watermarked\n3   Pneumonia can be caused by viruses, bacteria a...  watermarked\n6   Leaders have taken this issue to bigger office...  watermarked\n8   Bodaboda riders through their association can ...  watermarked\n10  The government has the power to influence acti...  watermarked","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Generated Text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Some companies failed to pay their workers dur...</td>\n      <td>watermarked</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pneumonia can be caused by viruses, bacteria a...</td>\n      <td>watermarked</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Leaders have taken this issue to bigger office...</td>\n      <td>watermarked</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Bodaboda riders through their association can ...</td>\n      <td>watermarked</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>The government has the power to influence acti...</td>\n      <td>watermarked</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import time\nimport torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nnltk.download('punkt')\n\n\nclass DipperParaphraser(object):\n    def __init__(self, model=\"kalpeshk2011/dipper-paraphraser-xxl\", verbose=True):\n        time1 = time.time()\n        self.tokenizer = T5Tokenizer.from_pretrained('google/t5-v1_1-xxl')\n        self.model = T5ForConditionalGeneration.from_pretrained(model)\n        if verbose:\n            print(f\"{model} model loaded in {time.time() - time1}\")\n#         self.model.cuda()\n        self.model.eval()\n\n    def paraphrase(self, input_text, lex_diversity, order_diversity, prefix=\"\", sent_interval=3, **kwargs):\n        \"\"\"Paraphrase a text using the DIPPER model.\n\n        Args:\n            input_text (str): The text to paraphrase. Make sure to mark the sentence to be paraphrased between <sent> and </sent> blocks, keeping space on either side.\n            lex_diversity (int): The lexical diversity of the output, choose multiples of 20 from 0 to 100. 0 means no diversity, 100 means maximum diversity.\n            order_diversity (int): The order diversity of the output, choose multiples of 20 from 0 to 100. 0 means no diversity, 100 means maximum diversity.\n            **kwargs: Additional keyword arguments like top_p, top_k, max_length.\n        \"\"\"\n        assert lex_diversity in [0, 20, 40, 60, 80, 100], \"Lexical diversity must be one of 0, 20, 40, 60, 80, 100.\"\n        assert order_diversity in [0, 20, 40, 60, 80, 100], \"Order diversity must be one of 0, 20, 40, 60, 80, 100.\"\n\n        lex_code = int(100 - lex_diversity)\n        order_code = int(100 - order_diversity)\n\n        input_text = \" \".join(input_text.split())\n        sentences = sent_tokenize(input_text)\n        prefix = \" \".join(prefix.replace(\"\\n\", \" \").split())\n        output_text = \"\"\n\n        for sent_idx in range(0, len(sentences), sent_interval):\n            curr_sent_window = \" \".join(sentences[sent_idx:sent_idx + sent_interval])\n            final_input_text = f\"lexical = {lex_code}, order = {order_code}\"\n            if prefix:\n                final_input_text += f\" {prefix}\"\n            final_input_text += f\" <sent> {curr_sent_window} </sent>\"\n\n            final_input = self.tokenizer([final_input_text], return_tensors=\"pt\")\n            final_input = {k: v for k, v in final_input.items()}\n\n            with torch.inference_mode():\n                outputs = self.model.generate(**final_input, **kwargs)\n            outputs = self.tokenizer.batch_decode(outputs, skip_special_tokens=True)\n            prefix += \" \" + outputs[0]\n            output_text += \" \" + outputs[0]\n\n        return output_text\n\nif __name__ == \"__main__\":\n    # Example usage\n    # dp = DipperParaphraser(model=\"/work/kalpeshkrish_umass_edu/better-paraphrases/para-paraphrase-ctx-t5-xxl\")\n    dp = DipperParaphraser(model=\"kalpeshk2011/dipper-paraphraser-xxl\")\n\n    prompt = \"Tracy is a fox.\"\n    input_text = \"It is quick and brown. It jumps over the lazy dog.\"\n\n    output_l60_o60_greedy = dp.paraphrase(input_text, lex_diversity=80, order_diversity=60, prefix=prompt, do_sample=False, max_length=512)\n    output_l60_sample = dp.paraphrase(input_text, lex_diversity=80, order_diversity=0, prefix=prompt, do_sample=True, top_p=0.75, top_k=None, max_length=512)\n    print(f\"Input = {prompt} <sent> {input_text} </sent>\\n\")\n    print(f\"Output (Lexical diversity = 80, Order diversity = 60, Greedy) = {output_l60_o60_greedy}\\n\")\n    print(f\"Output (Lexical diversity = 80, Sample p = 0.75) = {output_l60_sample}\\n\")\n    print(\"--------------------\\n\")\n\n    prompt = \"In a shocking finding, scientist discovered a herd of unicorns living in a remote valley.\"\n    input_text = \"They have never been known to mingle with humans. Today, it is believed these unicorns live in an unspoilt environment which is surrounded by mountains. Its edge is protected by a thick wattle of wattle trees, giving it a majestic appearance. Along with their so-called miracle of multicolored coat, their golden coloured feather makes them look like mirages. Some of them are rumored to be capable of speaking a large amount of different languages. They feed on elk and goats as they were selected from those animals that possess a fierceness to them, and can \\\"eat\\\" them with their long horns.\"\n\n    print(f\"Input = {prompt} <sent> {data} </sent>\\n\")\n    output_l60_sample = dp.paraphrase(data, lex_diversity=60, order_diversity=0, prefix=prompt, do_sample=True, top_p=0.75, top_k=None, max_length=512)\n    print(f\"Output (Lexical diversity = 60, Sample p = 0.75) = {output_l60_sample}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T12:48:28.509828Z","iopub.execute_input":"2024-04-14T12:48:28.510084Z","iopub.status.idle":"2024-04-14T12:48:48.716749Z","shell.execute_reply.started":"2024-04-14T12:48:28.510058Z","shell.execute_reply":"2024-04-14T12:48:48.715795Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nLoading checkpoint shards: 100%|██████████| 5/5 [00:10<00:00,  2.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"kalpeshk2011/dipper-paraphraser-xxl model loaded in 13.709600448608398\nInput = Tracy is a fox. <sent> It is quick and brown. It jumps over the lazy dog. </sent>\n\nOutput (Lexical diversity = 80, Order diversity = 60, Greedy) =  She jumps over the lazy dog. She is brown and quick.\n\nOutput (Lexical diversity = 80, Sample p = 0.75) =  It is agile and brown. It jumps over the lazy dog.\n\n--------------------\n\nInput = In a shocking finding, scientist discovered a herd of unicorns living in a remote valley. <sent>                                          Generated Text        label\n1     Some companies failed to pay their workers dur...  watermarked\n3     Pneumonia can be caused by viruses, bacteria a...  watermarked\n6     Leaders have taken this issue to bigger office...  watermarked\n8     Bodaboda riders through their association can ...  watermarked\n10    The government has the power to influence acti...  watermarked\n...                                                 ...          ...\n1985  This is my responsibility as the President of ...  watermarked\n1987  Corona patients are under government observati...  watermarked\n1989  Most shop owners dodge tax payments.  Not many...  watermarked\n1990  She handed in incomplete documents which led t...  watermarked\n1997  The public needs awareness on how to maintain ...  watermarked\n\n[1000 rows x 2 columns] </sent>\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_13/3492054859.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"In a shocking finding, scientist discovered a herd of unicorns living in a remote valley.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"They have never been known to mingle with humans. Today, it is believed these unicorns live in an unspoilt environment which is surrounded by mountains. Its edge is protected by a thick wattle of wattle trees, giving it a majestic appearance. Along with their so-called miracle of multicolored coat, their golden coloured feather makes them look like mirages. Some of them are rumored to be capable of speaking a large amount of different languages. They feed on elk and goats as they were selected from those animals that possess a fierceness to them, and can \\\"eat\\\" them with their long horns.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Input = {prompt} <sent> {data} </sent>\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0moutput_l60_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparaphrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex_diversity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder_diversity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Output (Lexical diversity = 60, Sample p = 0.75) = {output_l60_sample}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_13/3492054859.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, input_text, lex_diversity, order_diversity, prefix, sent_interval, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mlex_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlex_diversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0morder_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0morder_diversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moutput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6289\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6290\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6291\u001b[0m         ):\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'split'"],"ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'split'","output_type":"error"}]}]}