{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# How to Run MMLU with Generative Models (Hugging Face Transformers)\nBased on: https://github.com/FranxYao/chain-of-thought-hub/blob/main/MMLU/run_mmlu_open_source.py","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport time\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport gc","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:51:14.537097Z","iopub.execute_input":"2024-05-07T16:51:14.537524Z","iopub.status.idle":"2024-05-07T16:51:14.542865Z","shell.execute_reply.started":"2024-05-07T16:51:14.537495Z","shell.execute_reply":"2024-05-07T16:51:14.541791Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/FranxYao/chain-of-thought-hub","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:51:14.544218Z","iopub.execute_input":"2024-05-07T16:51:14.544515Z","iopub.status.idle":"2024-05-07T16:51:15.532229Z","shell.execute_reply.started":"2024-05-07T16:51:14.544482Z","shell.execute_reply":"2024-05-07T16:51:15.531222Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"fatal: destination path 'chain-of-thought-hub' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"HF_CACHE_LOCATION = \"/data/shk148/models/opt/cache\"\n\nTASKS = [\n        'abstract_algebra',\n        'anatomy',\n        'astronomy',\n        'business_ethics',\n        'clinical_knowledge',\n        'college_biology',\n        'college_chemistry',\n        'college_computer_science',\n        'college_mathematics',\n        'college_medicine',\n        'college_physics',\n        'computer_security',\n        'conceptual_physics',\n        'econometrics',\n        'electrical_engineering',\n        'elementary_mathematics',\n        'formal_logic',\n        'global_facts',\n        'high_school_biology',\n        'high_school_chemistry',\n        'high_school_computer_science',\n        'high_school_european_history',\n        'high_school_geography',\n        'high_school_government_and_politics',\n        'high_school_macroeconomics',\n        'high_school_mathematics',\n        'high_school_microeconomics',\n        'high_school_physics',\n        'high_school_psychology',\n        'high_school_statistics',\n        'high_school_us_history',\n        'high_school_world_history',\n        'human_aging',\n        'human_sexuality',\n        'international_law',\n        'jurisprudence',\n        'logical_fallacies',\n        'machine_learning',\n        'management',\n        'marketing',\n        'medical_genetics',\n        'miscellaneous',\n        'moral_disputes',\n        'moral_scenarios',\n        'nutrition',\n        'philosophy',\n        'prehistory',\n        'professional_accounting',\n        'professional_law',\n        'professional_medicine',\n        'professional_psychology',\n        'public_relations',\n        'security_studies', \n        'sociology',\n        'us_foreign_policy',\n        'virology',\n        'world_religions'\n        ]\n\nchoices = [\"A\", \"B\", \"C\", \"D\"]\nDATA_DIR = \"/kaggle/working/chain-of-thought-hub/MMLU/data/\"","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:51:15.534248Z","iopub.execute_input":"2024-05-07T16:51:15.534564Z","iopub.status.idle":"2024-05-07T16:51:15.542934Z","shell.execute_reply.started":"2024-05-07T16:51:15.534534Z","shell.execute_reply":"2024-05-07T16:51:15.541991Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Helper Functions: Largely unchanged from https://github.com/FranxYao/chain-of-thought-hub/blob/main/MMLU/run_mmlu_open_source.py\n\ndef compute_metric(output_filename):\n    with open(output_filename, 'r') as f:\n        run_results = json.load(f)\n    total_acc = 0\n    total_num = 0\n    for task in run_results:\n        acc = 0\n        pred_answers = run_results[task]['pred_answers']\n        gold_answers = run_results[task]['gold_answers']\n        for pred, gold in zip(pred_answers, gold_answers):\n            if pred == gold: acc += 1\n        print(\"ACC-%s: %.4f\" % (task, acc/len(gold_answers)))\n        total_acc += acc\n        total_num += len(gold_answers)\n    print(\"ACC-all: %.4f\" % (total_acc/total_num))\n\n\ndef format_subject(subject):\n    l = subject.split(\"_\")\n    s = \"\"\n    for entry in l:\n        s += \" \" + entry\n    return s\n\ndef format_example(df, idx, include_answer=True):\n    prompt = df.iloc[idx, 0]\n    k = df.shape[1] - 2\n    for j in range(k):\n        prompt += \"\\n{}. {}\".format(choices[j], df.iloc[idx, j+1])\n    prompt += \"\\nAnswer:\"\n    if include_answer:\n        prompt += \" {}\\n\\n\".format(df.iloc[idx, k + 1])\n    return prompt\n\ndef gen_prompt(train_df, subject, k=-1):\n    prompt = \"The following are multiple choice questions (with answers) about {}.\\n\\n\".format(format_subject(subject))\n    if k == -1:\n        k = train_df.shape[0]\n    for i in range(k):\n        prompt += format_example(train_df, i)\n    return prompt\n\ndef prepare_input(tokenizer, prompts):\n    input_tokens = tokenizer.batch_encode_plus(prompts, return_tensors=\"pt\", padding=True)\n    input_tokens = {k:input_tokens[k] for k in input_tokens if k in [\"input_ids\", \"attention_mask\"]}\n    for t in input_tokens:\n        if torch.is_tensor(input_tokens[t]):\n            input_tokens[t] = input_tokens[t].to('cuda')\n\n    return input_tokens\n\ndef batch_split(prompts, batch_num):\n    batch_prompts = []\n    mini_batch = []\n    for prompt in prompts:\n        mini_batch.append(prompt)\n        if len(mini_batch) == batch_num:\n            batch_prompts.append(mini_batch)\n            mini_batch = []\n    if len(mini_batch) != 0:\n        batch_prompts.append(mini_batch)\n    return batch_prompts\n\ndef batch_infer(model, tokenizer, prompts):\n    batch_size = 8\n    answers = []\n    for batch_input in tqdm(batch_split(prompts, batch_size)):\n        encode_inputs = prepare_input(tokenizer, batch_input)\n        outputs = model.generate(**encode_inputs, max_new_tokens=1, pad_token_id=tokenizer.pad_token_id)\n        answers.extend(tokenizer.batch_decode(outputs, skip_special_tokens=True))\n    answers = [answer[-1] for answer in answers]\n    return answers\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:51:15.544124Z","iopub.execute_input":"2024-05-07T16:51:15.544396Z","iopub.status.idle":"2024-05-07T16:51:15.561332Z","shell.execute_reply.started":"2024-05-07T16:51:15.544373Z","shell.execute_reply":"2024-05-07T16:51:15.560561Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def load(checkpoint, model_type):\n    n_gpus = torch.cuda.device_count()\n    \n    model = AutoModelForCausalLM.from_pretrained(checkpoint, cache_dir=HF_CACHE_LOCATION).cuda()\n    tokenizer = AutoTokenizer.from_pretrained(checkpoint, cache_dir=HF_CACHE_LOCATION, padding_side='left')      \n    model.eval()\n    return model, tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:51:15.563103Z","iopub.execute_input":"2024-05-07T16:51:15.563376Z","iopub.status.idle":"2024-05-07T16:51:15.575229Z","shell.execute_reply.started":"2024-05-07T16:51:15.563352Z","shell.execute_reply":"2024-05-07T16:51:15.574402Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def main(ckpt_dir: str, param_size: str, model_type: str):\n    \n    run_results = {}\n    output_filename = 'run_results_%s_%sb.json' % (model_type, param_size)\n    \n    model, tokenizer = load(ckpt_dir, model_type)\n    start_time = time.time()\n    for task in TASKS:\n        print('Testing %s ...' % task)\n        records = []\n        dev_df = pd.read_csv(os.path.join(DATA_DIR, \"dev\", task + \"_dev.csv\"), header=None)[:5]\n        test_df = pd.read_csv(os.path.join(DATA_DIR, \"test\", task + \"_test.csv\"), header=None)\n        for i in range(test_df.shape[0]):\n            # get prompt and make sure it fits\n            k = 5\n            prompt_end = format_example(test_df, i, include_answer=False)\n            train_prompt = gen_prompt(dev_df, task, k)\n            prompt = train_prompt + prompt_end\n            while len(tokenizer.tokenize(prompt)) + 1> 2048: # bos token\n                prompt_split = prompt.split(\"\\n\\n\")\n                prompt_split.pop(1)\n                prompt = '\\n\\n'.join(prompt_split)\n            label = test_df.iloc[i, test_df.shape[1]-1]\n            records.append({'prompt':prompt, 'answer':label})\n\n        pred_answers = batch_infer(model, tokenizer, [record['prompt'] for record in records])\n        gold_answers = [record['answer'] for record in records]\n        run_results[task] = {'pred_answers':pred_answers, 'gold_answers':gold_answers}\n    with open(output_filename, 'w') as f:\n        json.dump(run_results, f, ensure_ascii=False, indent=2)\n    \n    compute_metric(output_filename)\n    end_time = time.time()\n    print(\"total run time %.2f\" % (end_time - start_time))\n    del model\n    del tokenizer\n    return (end_time - start_time)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:51:15.576200Z","iopub.execute_input":"2024-05-07T16:51:15.576454Z","iopub.status.idle":"2024-05-07T16:51:15.587879Z","shell.execute_reply.started":"2024-05-07T16:51:15.576431Z","shell.execute_reply":"2024-05-07T16:51:15.587126Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\ndraft_models = [\n\t\"facebook/opt-350m\"\n]\nrslt = dict()\n\nfor draft_model in draft_models:\n    rslt[draft_model] =  main(draft_model, draft_model.replace(\"facebook/opt-\", \"\"), \"OPT\")\n    gc.collect()\n    torch.cuda.empty_cache()\nprint(rslt)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T16:51:15.588864Z","iopub.execute_input":"2024-05-07T16:51:15.589143Z","iopub.status.idle":"2024-05-07T17:18:12.999799Z","shell.execute_reply.started":"2024-05-07T16:51:15.589120Z","shell.execute_reply":"2024-05-07T17:18:12.998876Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Testing abstract_algebra ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:06<00:00,  1.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing anatomy ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 17/17 [00:07<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing astronomy ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 19/19 [00:12<00:00,  1.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing business_ethics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:07<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing clinical_knowledge ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 34/34 [00:14<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing college_biology ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 18/18 [00:09<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing college_chemistry ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:07<00:00,  1.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing college_computer_science ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:12<00:00,  1.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing college_mathematics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:08<00:00,  1.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing college_medicine ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 22/22 [00:18<00:00,  1.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing college_physics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:07<00:00,  1.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing computer_security ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:05<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing conceptual_physics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [00:08<00:00,  3.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing econometrics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 15/15 [00:10<00:00,  1.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing electrical_engineering ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 19/19 [00:07<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing elementary_mathematics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 48/48 [00:25<00:00,  1.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing formal_logic ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:11<00:00,  1.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing global_facts ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:05<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_biology ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 39/39 [00:22<00:00,  1.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_chemistry ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26/26 [00:13<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_computer_science ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:14<00:00,  1.12s/it]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_european_history ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [01:02<00:00,  2.96s/it]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_geography ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 25/25 [00:09<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_government_and_politics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 25/25 [00:11<00:00,  2.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_macroeconomics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 49/49 [00:19<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_mathematics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 34/34 [00:18<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_microeconomics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_physics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 19/19 [00:11<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_psychology ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 69/69 [00:38<00:00,  1.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_statistics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 27/27 [00:25<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_us_history ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26/26 [01:16<00:00,  2.94s/it]\n","output_type":"stream"},{"name":"stdout","text":"Testing high_school_world_history ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [01:06<00:00,  2.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"Testing human_aging ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28/28 [00:08<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing human_sexuality ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 17/17 [00:05<00:00,  2.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing international_law ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 16/16 [00:10<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing jurisprudence ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [00:05<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing logical_fallacies ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [00:09<00:00,  2.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing machine_learning ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [00:10<00:00,  1.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing management ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:03<00:00,  3.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing marketing ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 30/30 [00:12<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing medical_genetics ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:04<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing miscellaneous ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 98/98 [00:31<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing moral_disputes ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44/44 [00:22<00:00,  1.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing moral_scenarios ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 112/112 [01:17<00:00,  1.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing nutrition ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 39/39 [00:24<00:00,  1.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing philosophy ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 39/39 [00:14<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing prehistory ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 41/41 [00:22<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing professional_accounting ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 36/36 [00:25<00:00,  1.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing professional_law ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 192/192 [08:13<00:00,  2.57s/it]\n","output_type":"stream"},{"name":"stdout","text":"Testing professional_medicine ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 34/34 [00:51<00:00,  1.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Testing professional_psychology ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 77/77 [00:50<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing public_relations ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 14/14 [00:06<00:00,  2.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing security_studies ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 31/31 [00:50<00:00,  1.64s/it]\n","output_type":"stream"},{"name":"stdout","text":"Testing sociology ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 26/26 [00:11<00:00,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing us_foreign_policy ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [00:05<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing virology ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21/21 [00:07<00:00,  2.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Testing world_religions ...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 22/22 [00:05<00:00,  3.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"ACC-abstract_algebra: 0.2200\nACC-anatomy: 0.2667\nACC-astronomy: 0.1776\nACC-business_ethics: 0.2100\nACC-clinical_knowledge: 0.2679\nACC-college_biology: 0.2361\nACC-college_chemistry: 0.3200\nACC-college_computer_science: 0.2800\nACC-college_mathematics: 0.2700\nACC-college_medicine: 0.2486\nACC-college_physics: 0.2157\nACC-computer_security: 0.1900\nACC-conceptual_physics: 0.3064\nACC-econometrics: 0.2281\nACC-electrical_engineering: 0.3310\nACC-elementary_mathematics: 0.2566\nACC-formal_logic: 0.2778\nACC-global_facts: 0.1900\nACC-high_school_biology: 0.3000\nACC-high_school_chemistry: 0.3153\nACC-high_school_computer_science: 0.1800\nACC-high_school_european_history: 0.2606\nACC-high_school_geography: 0.3586\nACC-high_school_government_and_politics: 0.3472\nACC-high_school_macroeconomics: 0.2897\nACC-high_school_mathematics: 0.2778\nACC-high_school_microeconomics: 0.2773\nACC-high_school_physics: 0.3377\nACC-high_school_psychology: 0.3358\nACC-high_school_statistics: 0.4722\nACC-high_school_us_history: 0.2304\nACC-high_school_world_history: 0.2068\nACC-human_aging: 0.1480\nACC-human_sexuality: 0.2519\nACC-international_law: 0.3719\nACC-jurisprudence: 0.2315\nACC-logical_fallacies: 0.2515\nACC-machine_learning: 0.2054\nACC-management: 0.2136\nACC-marketing: 0.1966\nACC-medical_genetics: 0.3000\nACC-miscellaneous: 0.2031\nACC-moral_disputes: 0.2399\nACC-moral_scenarios: 0.2536\nACC-nutrition: 0.2549\nACC-philosophy: 0.2026\nACC-prehistory: 0.2870\nACC-professional_accounting: 0.2411\nACC-professional_law: 0.2216\nACC-professional_medicine: 0.4485\nACC-professional_psychology: 0.2565\nACC-public_relations: 0.2000\nACC-security_studies: 0.4041\nACC-sociology: 0.2388\nACC-us_foreign_policy: 0.2600\nACC-virology: 0.1928\nACC-world_religions: 0.1754\nACC-all: 0.2611\ntotal run time 1615.54\n{'facebook/opt-350m': 1615.5412158966064}\n","output_type":"stream"}]}]}